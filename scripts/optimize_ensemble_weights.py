# -*- coding: utf-8 -*-
"""
ì•™ìƒë¸” ê°€ì¤‘ì¹˜ ìµœì í™” ìŠ¤í¬ë¦½íŠ¸ (ê³ ì†í™” ë²„ì „)

ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ê³¼ì í•© ë¶„ì„ ê²°ê³¼ë¥¼ í™œìš©í•˜ì—¬ ìµœì  ì•™ìƒë¸” ê°€ì¤‘ì¹˜ë¥¼ íƒìƒ‰í•©ë‹ˆë‹¤.
Grid Search ë°©ì‹ìœ¼ë¡œ ê° ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ë¥¼ ìµœì í™”í•©ë‹ˆë‹¤.
"""
from __future__ import annotations

import sys
import warnings
from datetime import datetime
from itertools import product
from pathlib import Path
from typing import Dict, List, Optional, Tuple

warnings.filterwarnings('ignore')

import numpy as np
import pandas as pd
import yaml
from tqdm import tqdm

PROJECT_ROOT = Path(__file__).resolve().parents[1]
sys.path.insert(0, str(PROJECT_ROOT))

from src.components.ranking.score_engine import build_score_total
from src.utils.config import load_config
from src.utils.io import load_artifact


# í‰ê°€ ì§€í‘œ ê³„ì‚° í•¨ìˆ˜ë“¤
def calculate_hit_ratio(scores: pd.Series, returns: pd.Series, top_k: int = 20) -> float:
    """Hit Ratio: ìƒìœ„ top_kê°œ ì¢…ëª©ì˜ ìŠ¹ë¥ """
    if len(scores) == 0 or len(returns) == 0:
        return np.nan
    top_k_idx = scores.nlargest(top_k).index
    top_k_returns = returns.loc[top_k_idx]
    hit_ratio = (top_k_returns > 0).mean()
    return float(hit_ratio) if not np.isnan(hit_ratio) else np.nan

def calculate_ic(scores: pd.Series, returns: pd.Series) -> float:
    """IC (Information Coefficient): Pearson ìƒê´€ê³„ìˆ˜"""
    if len(scores) == 0 or len(returns) == 0:
        return np.nan
    valid_idx = scores.notna() & returns.notna()
    if valid_idx.sum() < 2:
        return np.nan
    s = pd.to_numeric(scores[valid_idx], errors='coerce')
    r = pd.to_numeric(returns[valid_idx], errors='coerce')
    final_valid = s.notna() & r.notna()
    if final_valid.sum() < 2:
        return np.nan
    s = s[final_valid]
    r = r[final_valid]
    if s.std() == 0 or r.std() == 0:
        return np.nan
    corr = s.corr(r)
    return float(corr) if not np.isnan(corr) else np.nan

def calculate_icir(ic_series: pd.Series) -> float:
    """ICIR: ICì˜ ì•ˆì •ì„± (mean / std)"""
    if len(ic_series) == 0:
        return np.nan
    ic_valid = ic_series.dropna()
    if len(ic_valid) == 0:
        return np.nan
    ic_mean = ic_valid.mean()
    ic_std = ic_valid.std()
    if ic_std == 0 or np.isnan(ic_std) or np.isnan(ic_mean):
        return np.nan
    icir = ic_mean / ic_std
    return float(icir) if not np.isnan(icir) else np.nan

def calculate_forward_returns(panel_data: pd.DataFrame, horizon: str) -> pd.DataFrame:
    """ë¯¸ë˜ ìˆ˜ìµë¥  ê³„ì‚°"""
    df = panel_data.copy()
    periods = 20 if horizon == 'short' else 120

    # ì¢…ëª©ë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ë¯¸ë˜ ìˆ˜ìµë¥  ê³„ì‚°
    def calc_fwd_ret(group):
        prices = group['close'].pct_change(periods).shift(-periods)
        return prices

    df[f'ret_fwd_{periods}d'] = df.groupby('ticker').apply(calc_fwd_ret).reset_index(level=0, drop=True)

    return df


def calculate_objective_score(
    hit_ratio: float,
    ic_mean: float,
    icir: float,
    horizon: str = 'short'
) -> float:
    """
    ëª©ì í•¨ìˆ˜ ê³„ì‚° (ë‹¨ê¸°/ì¥ê¸°ë³„ ê°€ì¤‘ì¹˜ ì ìš©)
    """
    if horizon == 'short':
        # ë‹¨ê¸°: Hit Ratio 40% + IC Mean 30% + ICIR 30%
        weights = {'hit': 0.4, 'ic': 0.3, 'icir': 0.3}
    else:
        # ì¥ê¸°: IC Mean 50% + ICIR 30% + Hit Ratio 20%
        weights = {'hit': 0.2, 'ic': 0.5, 'icir': 0.3}

    # NaN ì²˜ë¦¬
    hit_ratio = hit_ratio if not np.isnan(hit_ratio) else 0.0
    ic_mean = ic_mean if not np.isnan(ic_mean) else 0.0
    icir = icir if not np.isnan(icir) else 0.0

    objective = (
        weights['hit'] * hit_ratio +
        weights['ic'] * max(0, ic_mean) +  # ICëŠ” ì–‘ìˆ˜ë§Œ ê³ ë ¤
        weights['icir'] * max(0, icir)    # ICIRë„ ì–‘ìˆ˜ë§Œ ê³ ë ¤
    )

    return float(objective)

def generate_ensemble_ranking_fast(
    model_rankings: Dict[str, pd.DataFrame],
    weights: Dict[str, float]
) -> pd.DataFrame:
    """
    ì•™ìƒë¸” ë­í‚¹ ìƒì„± (ê³ ì† ë²¡í„°í™” ë²„ì „)

    Args:
        model_rankings: ëª¨ë¸ë³„ ë­í‚¹ ì ìˆ˜ {'grid': df, 'ridge': df, 'xgboost': df, 'rf': df}
        weights: ëª¨ë¸ë³„ ê°€ì¤‘ì¹˜ {'grid': 0.4, 'ridge': 0.3, 'xgboost': 0.2, 'rf': 0.1}

    Returns:
        ì•™ìƒë¸” ë­í‚¹ DataFrame (date, ticker, score_ensemble)
    """
    # ê°€ì¤‘ì¹˜ ì •ê·œí™”
    total_weight = sum(weights.values())
    if abs(total_weight) > 1e-10:
        normalized_weights = {k: v / total_weight for k, v in weights.items()}
    else:
        n_models = len(weights)
        normalized_weights = {k: 1.0 / n_models for k in weights.keys()}

    # Pivot í…Œì´ë¸” ìƒì„± ë° ê°€ì¤‘ í•©ì‚° (ë²¡í„°í™”)
    weighted_scores = []
    for model_name, weight in normalized_weights.items():
        if model_name in model_rankings and weight > 0:
            df = model_rankings[model_name].copy()
            df['weighted_score'] = df['score'] * weight
            weighted_scores.append(df[['date', 'ticker', 'weighted_score']])

    if not weighted_scores:
        return pd.DataFrame(columns=['date', 'ticker', 'score_ensemble'])

    # ë³‘í•© ë° í•©ì‚°
    ensemble_df = weighted_scores[0].rename(columns={'weighted_score': 'score_ensemble'})
    for df in weighted_scores[1:]:
        ensemble_df = ensemble_df.merge(
            df, on=['date', 'ticker'], how='outer', suffixes=('', '_temp')
        )
        ensemble_df['score_ensemble'] = ensemble_df['score_ensemble'].fillna(0) + ensemble_df['weighted_score'].fillna(0)
        ensemble_df = ensemble_df.drop(columns=['weighted_score'])

    ensemble_df['score_ensemble'] = ensemble_df['score_ensemble'].fillna(0.5)

    return ensemble_df

def evaluate_ensemble(
    ensemble_ranking: pd.DataFrame,
    panel_data: pd.DataFrame,
    cv_folds: pd.DataFrame,
    horizon: str = 'short'
) -> Dict[str, float]:
    """ì•™ìƒë¸” ì„±ê³¼ í‰ê°€"""
    target_col = 'ret_fwd_20d' if horizon == 'short' else 'ret_fwd_120d'

    # Dev/Holdout êµ¬ê°„ ë¶„ë¦¬
    if 'segment' in cv_folds.columns:
        dev_folds = cv_folds[cv_folds['segment'] == 'dev']
        holdout_folds = cv_folds[cv_folds['segment'] == 'holdout']
    else:
        dev_folds = cv_folds[~cv_folds['fold_id'].str.startswith('holdout')]
        holdout_folds = cv_folds[cv_folds['fold_id'].str.startswith('holdout')]

    dev_dates = dev_folds['test_end'].unique()
    holdout_dates = holdout_folds['test_end'].unique()

    # í‰ê°€ í•¨ìˆ˜
    def evaluate_dates(dates):
        ics, hits = [], []
        for date in dates:
            date_data = panel_data[panel_data['date'] == date]
            ranking_data = ensemble_ranking[ensemble_ranking['date'] == date]

            if len(ranking_data) < 20:
                continue

            merged = date_data.merge(ranking_data, on=['date', 'ticker'], how='inner')
            if len(merged) < 20:
                continue

            ic = calculate_ic(merged['score_ensemble'], merged[target_col])
            hit = calculate_hit_ratio(merged['score_ensemble'], merged[target_col], top_k=20)

            if not np.isnan(ic):
                ics.append(ic)
            if not np.isnan(hit):
                hits.append(hit)

        return ics, hits

    # Dev í‰ê°€
    dev_ics, dev_hits = evaluate_dates(dev_dates)
    dev_ic_mean = np.mean(dev_ics) if len(dev_ics) > 0 else np.nan
    dev_icir = calculate_icir(pd.Series(dev_ics)) if len(dev_ics) > 0 else np.nan
    dev_hit_ratio = np.mean(dev_hits) if len(dev_hits) > 0 else np.nan

    # Holdout í‰ê°€
    holdout_ics, holdout_hits = evaluate_dates(holdout_dates)
    holdout_ic_mean = np.mean(holdout_ics) if len(holdout_ics) > 0 else np.nan
    holdout_icir = calculate_icir(pd.Series(holdout_ics)) if len(holdout_ics) > 0 else np.nan
    holdout_hit_ratio = np.mean(holdout_hits) if len(holdout_hits) > 0 else np.nan

    # ëª©ì í•¨ìˆ˜
    dev_objective = calculate_objective_score(dev_hit_ratio, dev_ic_mean, dev_icir, horizon)
    holdout_objective = calculate_objective_score(holdout_hit_ratio, holdout_ic_mean, holdout_icir, horizon)

    return {
        'dev_ic_mean': dev_ic_mean,
        'dev_icir': dev_icir,
        'dev_hit_ratio': dev_hit_ratio,
        'dev_objective': dev_objective,
        'holdout_ic_mean': holdout_ic_mean,
        'holdout_icir': holdout_icir,
        'holdout_hit_ratio': holdout_hit_ratio,
        'holdout_objective': holdout_objective,
        'ic_diff': holdout_ic_mean - dev_ic_mean if not (np.isnan(holdout_ic_mean) or np.isnan(dev_ic_mean)) else np.nan,
        'objective_diff': holdout_objective - dev_objective if not (np.isnan(holdout_objective) or np.isnan(dev_objective)) else np.nan
    }

def generate_model_rankings(
    panel_data: pd.DataFrame,
    horizon: str = 'short'
) -> Dict[str, pd.DataFrame]:
    """
    ê° ëª¨ë¸ë³„ ë­í‚¹ ì ìˆ˜ ìƒì„±
    """
    cfg = load_config('configs/config.yaml')
    base_dir = Path(cfg['paths']['base_dir'])
    configs_dir = base_dir / 'configs'

    # ëª¨ë¸ ì„¤ì • íŒŒì¼ë“¤
    model_configs = {
        'grid': None,  # ìµœì‹  íŒŒì¼ ì°¾ê¸°
        'ridge': None,
        'xgboost': None,
        'rf': configs_dir / f'feature_weights_{horizon}_rf_20260108_204232.yaml'
    }

    # Grid Search ìµœì‹  íŒŒì¼ ì°¾ê¸°
    grid_pattern = f'feature_groups_{horizon}_optimized_grid_*.yaml'
    grid_files = list(configs_dir.glob(grid_pattern))
    if grid_files:
        model_configs['grid'] = max(grid_files, key=lambda x: x.stat().st_mtime)
        print(f"  Grid Search ìµœì‹  íŒŒì¼: {model_configs['grid'].name}")
    else:
        print("  Grid Search íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")

    # ìµœì‹  íŒŒì¼ ì°¾ê¸°
    for key in ['ridge', 'xgboost']:
        pattern = f'feature_weights_{horizon}_{key}_*.yaml'
        files = list(configs_dir.glob(pattern))
        print(f"  {key.upper()} íŒŒì¼ ê²€ìƒ‰ íŒ¨í„´: {pattern}")
        print(f"  ë°œê²¬ëœ íŒŒì¼ ìˆ˜: {len(files)}")
        if files:
            latest_file = max(files, key=lambda x: x.stat().st_mtime)
            model_configs[key] = latest_file
            print(f"  ìµœì‹  íŒŒì¼: {latest_file.name}")
        else:
            print(f"  {key.upper()} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")

    rankings = {}

    # Grid Search ë­í‚¹
    if model_configs['grid'].exists():
        try:
            rankings['grid'] = build_score_total(
                panel_data,
                feature_groups_config=model_configs['grid'],
                normalization_method='percentile',
                date_col='date'
            )
            rankings['grid'] = rankings['grid'][['date', 'ticker', 'score_total']].rename(columns={'score_total': 'score'})
            print(f"  Grid Search ë­í‚¹ ìƒì„±: {len(rankings['grid'])}ê°œ")
        except Exception as e:
            print(f"  âš ï¸ Grid Search ë­í‚¹ ìƒì„± ì‹¤íŒ¨: {e}")

    # ML ëª¨ë¸ë“¤ ë­í‚¹ ì§ì ‘ ìƒì„±
    for model_name in ['ridge', 'xgboost', 'rf']:
        if model_configs[model_name] and model_configs[model_name].exists():
            try:
                # í”¼ì²˜ ê°€ì¤‘ì¹˜ ë¡œë“œ
                with open(model_configs[model_name], 'r', encoding='utf-8') as f:
                    weights_config = yaml.safe_load(f)

                # ë­í‚¹ ìƒì„±
                ranking_df = generate_ml_model_ranking(panel_data, weights_config, horizon)
                rankings[model_name] = ranking_df
                print(f"  {model_name.upper()} ë­í‚¹ ìƒì„±: {len(rankings[model_name])}ê°œ")
            except Exception as e:
                print(f"  âš ï¸ {model_name.upper()} ë­í‚¹ ìƒì„± ì‹¤íŒ¨: {e}")

    print(f"ìµœì¢… ë­í‚¹ ë”•ì…”ë„ˆë¦¬: {list(rankings.keys())}, ê¸¸ì´: {len(rankings)}")
    if rankings:
        print("âœ… rankings ë”•ì…”ë„ˆë¦¬ê°€ ë¹„ì–´ìˆì§€ ì•ŠìŠµë‹ˆë‹¤")
        return rankings
    else:
        print("âŒ rankings ë”•ì…”ë„ˆë¦¬ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
        return None

def generate_ml_model_ranking(panel_data: pd.DataFrame, weights_config: dict, horizon: str) -> pd.DataFrame:
    """
    ML ëª¨ë¸ ë­í‚¹ ìƒì„±
    """
    # í•„ìš”í•œ í”¼ì²˜ ì„ íƒ (OHLCV í¬í•¨)
    all_cols = [col for col in panel_data.columns
                if col not in ['date', 'ticker', 'ret_fwd_20d', 'ret_fwd_120d', 'split', 'phase', 'segment', 'fold_id', 'in_universe', 'ym', 'corp_code']
                and panel_data[col].dtype in [np.float64, np.float32, np.int64, np.int32]]

    if not all_cols:
        raise ValueError("ì‚¬ìš© ê°€ëŠ¥í•œ í”¼ì²˜ê°€ ì—†ìŠµë‹ˆë‹¤")

    # ê°€ì¤‘ì¹˜ ì¶”ì¶œ
    if 'weights' in weights_config:
        weights = weights_config['weights']
    elif 'feature_weights' in weights_config:
        weights = weights_config['feature_weights']
    else:
        # configì—ì„œ ì§ì ‘ ê°€ì¤‘ì¹˜ ì°¾ê¸°
        weights = {}
        for key, value in weights_config.items():
            if isinstance(value, (int, float)):
                weights[key] = value

    if not weights:
        raise ValueError("ê°€ì¤‘ì¹˜ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

    # ì ìˆ˜ ê³„ì‚°
    scores = np.zeros(len(panel_data))
    valid_features = []

    for feature, weight in weights.items():
        if feature in all_cols and feature in panel_data.columns:
            feature_values = panel_data[feature].fillna(0)
            scores += feature_values * weight
            valid_features.append(feature)

    if not valid_features:
        raise ValueError("ìœ íš¨í•œ í”¼ì²˜ê°€ ì—†ìŠµë‹ˆë‹¤")

    # ê²°ê³¼ DataFrame ìƒì„±
    result_df = panel_data[['date', 'ticker']].copy()
    result_df['score'] = scores

    # ì •ê·œí™” (ë­í‚¹ ëª©ì )
    result_df['score'] = (result_df['score'] - result_df['score'].mean()) / result_df['score'].std()

    return result_df

def optimize_ensemble_weights(
    horizon: str = 'short',
    weight_step: float = 0.1,
    max_weight: float = 1.0,
    max_combinations: int = 200
) -> pd.DataFrame:
    """
    ì•™ìƒë¸” ê°€ì¤‘ì¹˜ ìµœì í™” (Grid Search)

    Args:
        horizon: 'short' ë˜ëŠ” 'long'
        weight_step: ê°€ì¤‘ì¹˜ ê°„ê²©
        max_weight: ìµœëŒ€ ê°€ì¤‘ì¹˜
        max_combinations: ìµœëŒ€ í‰ê°€ ì¡°í•© ìˆ˜

    Returns:
        ìµœì í™” ê²°ê³¼ DataFrame
    """
    print("="*100)
    print(f"ğŸš€ ì•™ìƒë¸” ê°€ì¤‘ì¹˜ ìµœì í™” ({horizon.upper()} ì „ëµ) - {max_combinations}ê°œ ì¡°í•©")
    print("="*100)

    # ë°ì´í„° ë¡œë“œ
    cfg = load_config('configs/config.yaml')
    base_dir = Path(cfg['paths']['base_dir'])
    interim_dir = base_dir / 'data' / 'interim'

    panel_data = load_artifact(interim_dir / 'panel_merged_daily')
    cv_folds = load_artifact(interim_dir / f'cv_folds_{horizon}')

    print(f"ğŸ“Š ë°ì´í„°: íŒ¨ë„ {len(panel_data):,}í–‰, CV folds {len(cv_folds)}ê°œ")

    # ë¯¸ë˜ ìˆ˜ìµë¥  ê³„ì‚° (ì—†ëŠ” ê²½ìš°)
    target_col = 'ret_fwd_20d' if horizon == 'short' else 'ret_fwd_120d'
    if target_col not in panel_data.columns:
        print(f"âš ï¸ {target_col} ì»¬ëŸ¼ì´ ì—†ì–´ ê³„ì‚° ì¤‘...")
        panel_data = calculate_forward_returns(panel_data, horizon)
        print(f"âœ… {target_col} ì»¬ëŸ¼ ê³„ì‚° ì™„ë£Œ")

    # ëª¨ë¸ë³„ ë­í‚¹ ìƒì„±
    print("\n[1/3] ëª¨ë¸ë³„ ë­í‚¹ ìƒì„± ì¤‘...")
    model_rankings = generate_model_rankings(panel_data, horizon)

    if model_rankings is None or not model_rankings:
        print("âš ï¸ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ë­í‚¹ì´ ì—†ìŒ")
        return pd.DataFrame()

    available_models = list(model_rankings.keys())
    print(f"âœ… ìƒì„± ì™„ë£Œ: {available_models}")

    # ê°€ì¤‘ì¹˜ ì¡°í•© ìƒì„±
    print("\n[2/3] ê°€ì¤‘ì¹˜ ì¡°í•© ìƒì„± ì¤‘...")
    weight_values = np.arange(0, max_weight + weight_step, weight_step)

    combinations = []
    for w in product(weight_values, repeat=len(available_models)):
        if sum(w) > 0:
            total = sum(w)
            normalized = tuple(wi / total for wi in w)
            combinations.append(normalized)

    # ì¤‘ë³µ ì œê±°
    combinations = list(set(combinations))
    print(f"ì´ {len(combinations):,}ê°œ ì¡°í•© ìƒì„± â†’ {min(max_combinations, len(combinations))}ê°œ í‰ê°€")

    # í‰ê°€ ì‹¤í–‰
    print("\n[3/3] ì•™ìƒë¸” í‰ê°€ ì¤‘...")
    print("="*100)

    results = []
    import time
    start_time = time.time()

    # tqdm ì§„í–‰ë¥  ë°”
    pbar = tqdm(total=min(max_combinations, len(combinations)), desc="í‰ê°€ ì§„í–‰", ncols=100)

    for i, weights_tuple in enumerate(combinations[:max_combinations]):
        iteration_start = time.time()

        weights = dict(zip(available_models, weights_tuple))

        try:
            # ì•™ìƒë¸” ë­í‚¹ ìƒì„± (ê³ ì†)
            ensemble_ranking = generate_ensemble_ranking_fast(model_rankings, weights)

            if len(ensemble_ranking) == 0:
                pbar.update(1)
                continue

            # ì•™ìƒë¸” í‰ê°€
            metrics = evaluate_ensemble(ensemble_ranking, panel_data, cv_folds, horizon)

            result = {
                'horizon': horizon,
                **{f'weight_{model}': weight for model, weight in weights.items()},
                **metrics
            }
            results.append(result)

            # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸
            holdout_obj = metrics.get('holdout_objective', 0)
            pbar.set_postfix({
                'HoldoutObj': f"{holdout_obj:.4f}",
                'IC': f"{metrics.get('holdout_ic_mean', 0):.4f}",
                'ì‹œê°„/ì¡°í•©': f"{time.time() - iteration_start:.1f}s"
            })
            pbar.update(1)

            # ì¤‘ê°„ ì €ì¥ (ë§¤ 50ë²ˆë§ˆë‹¤)
            if (i + 1) % 50 == 0 and results:
                temp_df = pd.DataFrame(results)
                temp_file = base_dir / 'artifacts' / 'reports' / f'ensemble_optimization_{horizon}_intermediate_{i+1:04d}.csv'
                temp_df.to_csv(temp_file, index=False, encoding='utf-8-sig')
                tqdm.write(f"ğŸ’¾ ì¤‘ê°„ ì €ì¥: {temp_file.name}")

        except Exception as e:
            tqdm.write(f"âš ï¸ ì¡°í•© {i+1} í‰ê°€ ì‹¤íŒ¨: {str(e)[:80]}")
            pbar.update(1)
            continue

    pbar.close()

    print("\nâœ… ì•™ìƒë¸” í‰ê°€ ì™„ë£Œ!")
    total_time = time.time() - start_time
    print(f"â±ï¸  ì´ ì†Œìš”ì‹œê°„: {total_time/60:.1f}ë¶„ ({total_time:.1f}ì´ˆ)")

    results_df = pd.DataFrame(results)

    if len(results_df) == 0:
        print("âš ï¸ í‰ê°€ ê²°ê³¼ê°€ ì—†ìŒ")
        return pd.DataFrame()

    # ìµœì  ê²°ê³¼ ì„ íƒ
    best_result = results_df.loc[results_df['holdout_objective'].idxmax()]

    print("\n" + "="*100)
    print("ğŸ† ìµœì  ì•™ìƒë¸” ê°€ì¤‘ì¹˜:")
    print("="*100)
    for col in results_df.columns:
        if col.startswith('weight_'):
            model_name = col.replace('weight_', '').upper()
            weight = best_result[col]
            print(f"  {model_name:12s}: {weight:.3f}")

    print("\nğŸ“Š ìµœì  ì„±ê³¼:")
    print(f"  Holdout Obj  : {best_result['holdout_objective']:.4f}")
    print(f"  Holdout IC   : {best_result['holdout_ic_mean']:.4f}")
    print(f"  Holdout ICIR : {best_result['holdout_icir']:.4f}")
    print(f"  Holdout Hit  : {best_result['holdout_hit_ratio']:.1%}")
    print(f"  IC Diff      : {best_result['ic_diff']:.4f}")

    # ê²°ê³¼ ì €ì¥
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    output_file = base_dir / 'artifacts' / 'reports' / f'ensemble_optimization_{horizon}_{timestamp}.csv'
    results_df.to_csv(output_file, index=False, encoding='utf-8-sig')
    print(f"\nâœ… ê²°ê³¼ ì €ì¥: {output_file}")

    return results_df

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import argparse

    parser = argparse.ArgumentParser(description='ì•™ìƒë¸” ê°€ì¤‘ì¹˜ ìµœì í™”')
    parser.add_argument('--horizon', choices=['short', 'long', 'both'], default='short',
                       help='ì „ëµ ìœ í˜• (ê¸°ë³¸: short)')
    parser.add_argument('--weight-step', type=float, default=0.1,
                       help='ê°€ì¤‘ì¹˜ ê°„ê²© (ê¸°ë³¸: 0.1)')
    parser.add_argument('--max-weight', type=float, default=1.0,
                       help='ìµœëŒ€ ê°€ì¤‘ì¹˜ (ê¸°ë³¸: 1.0)')
    parser.add_argument('--combinations', type=int, default=200,
                       help='ìµœëŒ€ í‰ê°€ ì¡°í•© ìˆ˜ (ê¸°ë³¸: 200)')

    args = parser.parse_args()

    # ë‹¨ê¸° ì „ëµ
    if args.horizon in ['short', 'both']:
        optimize_ensemble_weights('short', args.weight_step, args.max_weight, args.combinations)

    # ì¥ê¸° ì „ëµ
    if args.horizon in ['long', 'both']:
        optimize_ensemble_weights('long', args.weight_step, args.max_weight, args.combinations)

def test_specific_weights(horizon: str, weight_sets: List[Dict[str, float]]):
    """íŠ¹ì • ê°€ì¤‘ì¹˜ ì¡°í•© í…ŒìŠ¤íŠ¸ (ê³¼ì í•© ê°œì„ ìš©)"""
    print(f"\n{'='*80}")
    print(f"ğŸ§ª íŠ¹ì • ê°€ì¤‘ì¹˜ ì¡°í•© í…ŒìŠ¤íŠ¸ ({horizon.upper()} ì „ëµ)")
    print(f"{'='*80}")

    # ë°ì´í„° ë¡œë“œ
    cfg = load_config('configs/config.yaml')
    base_dir = Path(cfg['paths']['base_dir'])
    interim_dir = base_dir / 'data' / 'interim'
    results = []

    print("\n[1/3] ë°ì´í„° ë¡œë“œ ì¤‘...")
    panel_data = load_artifact(interim_dir / 'panel_merged_daily')
    cv_folds = load_artifact(interim_dir / f'cv_folds_{horizon}')

    if panel_data is None or cv_folds is None:
        print("âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨")
        return pd.DataFrame()

    print(f"ğŸ“Š ë°ì´í„°: íŒ¨ë„ {len(panel_data):,d}í–‰, CV folds {len(cv_folds)}ê°œ")

    # ë¯¸ë˜ ìˆ˜ìµë¥  ê³„ì‚° (ì—†ëŠ” ê²½ìš°)
    target_col = 'ret_fwd_20d' if horizon == 'short' else 'ret_fwd_120d'
    if target_col not in panel_data.columns:
        print(f"âš ï¸ {target_col} ì»¬ëŸ¼ì´ ì—†ì–´ ê³„ì‚° ì¤‘...")
        panel_data = calculate_forward_returns(panel_data, horizon)
        print(f"âœ… {target_col} ì»¬ëŸ¼ ê³„ì‚° ì™„ë£Œ")

    # ëª¨ë¸ ë­í‚¹ ìƒì„±
    print("\n[2/3] ëª¨ë¸ë³„ ë­í‚¹ ìƒì„± ì¤‘...")
    model_rankings = generate_model_rankings(panel_data, horizon)
    if model_rankings is None or not model_rankings:
        print("âŒ ëª¨ë¸ ë­í‚¹ ìƒì„± ì‹¤íŒ¨")
        return pd.DataFrame()

    print(f"âœ… ìƒì„± ì™„ë£Œ: {list(model_rankings.keys())}")

    # íŠ¹ì • ê°€ì¤‘ì¹˜ ì¡°í•© í…ŒìŠ¤íŠ¸
    print(f"\n[3/3] {len(weight_sets)}ê°œ ê°€ì¤‘ì¹˜ ì¡°í•© í‰ê°€ ì¤‘...")
    for i, weights in enumerate(tqdm(weight_sets, desc="í‰ê°€ ì§„í–‰")):
        try:
            # ì•™ìƒë¸” ë­í‚¹ ìƒì„±
            ensemble_ranking = generate_ensemble_ranking_fast(model_rankings, weights)

            if len(ensemble_ranking) == 0:
                continue

            # ì•™ìƒë¸” í‰ê°€
            metrics = evaluate_ensemble(ensemble_ranking, panel_data, cv_folds, horizon)

            result = {
                'horizon': horizon,
                'test_set': f'improved_{i+1}',
                **{f'weight_{model}': weight for model, weight in weights.items()},
                **metrics
            }
            results.append(result)

        except Exception as e:
            tqdm.write(f"âš ï¸ ì¡°í•© {i+1} í‰ê°€ ì‹¤íŒ¨: {str(e)[:80]}")
            continue

    print("\nâœ… íŠ¹ì • ê°€ì¤‘ì¹˜ ì¡°í•© í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

    results_df = pd.DataFrame(results)

    if len(results_df) == 0:
        print("âš ï¸ í‰ê°€ ê²°ê³¼ê°€ ì—†ìŒ")
        return pd.DataFrame()

    # ê²°ê³¼ ì¶œë ¥
    print(f"\n{'='*80}")
    print("ğŸ§ª í…ŒìŠ¤íŠ¸ ê²°ê³¼:")
    print(f"{'='*80}")

    for idx, row in results_df.iterrows():
        print(f"\ní…ŒìŠ¤íŠ¸ ì„¸íŠ¸ {row['test_set']}:")
        for col in results_df.columns:
            if col.startswith('weight_'):
                model_name = col.replace('weight_', '').upper()
                weight = row[col]
                print(f"  {model_name:12s}: {weight:.3f}")
        print(f"  Holdout Obj  : {row['holdout_objective']:.4f}")
        print(f"  Holdout IC   : {row['holdout_ic_mean']:.4f}")
        print(f"  Holdout ICIR : {row['holdout_icir']:.4f}")
        print(f"  Holdout Hit  : {row['holdout_hit_ratio']:.1%}")
        print(f"  IC Diff      : {row['ic_diff']:.4f}")

    # ê²°ê³¼ ì €ì¥
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    output_file = base_dir / 'artifacts' / 'reports' / f'ensemble_improved_weights_{horizon}_{timestamp}.csv'
    results_df.to_csv(output_file, index=False, encoding='utf-8-sig')
    print(f"\nâœ… ê²°ê³¼ ì €ì¥: {output_file}")

    return results_df

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import argparse

    parser = argparse.ArgumentParser(description='ì•™ìƒë¸” ê°€ì¤‘ì¹˜ ìµœì í™”')
    parser.add_argument('--horizon', choices=['short', 'long', 'both'], default='short',
                       help='ì „ëµ ìœ í˜• (ê¸°ë³¸: short)')
    parser.add_argument('--weight-step', type=float, default=0.1,
                       help='ê°€ì¤‘ì¹˜ ê°„ê²© (ê¸°ë³¸: 0.1)')
    parser.add_argument('--max-weight', type=float, default=1.0,
                       help='ìµœëŒ€ ê°€ì¤‘ì¹˜ (ê¸°ë³¸: 1.0)')
    parser.add_argument('--combinations', type=int, default=200,
                       help='ìµœëŒ€ í‰ê°€ ì¡°í•© ìˆ˜ (ê¸°ë³¸: 200)')
    parser.add_argument('--test-improved', action='store_true',
                       help='ê³¼ì í•© ê°œì„ ëœ ê°€ì¤‘ì¹˜ ì¡°í•© í…ŒìŠ¤íŠ¸')

    args = parser.parse_args()

    if args.test_improved:
        # ê³¼ì í•© ê°œì„ ëœ ê°€ì¤‘ì¹˜ ì¡°í•© í…ŒìŠ¤íŠ¸
        improved_weights = {
            'short': [
                {'grid': 0.35, 'ridge': 0.57, 'xgboost': 0.08, 'rf': 0.00},  # XGBoost ê°ì†Œ, Ridge ì¦ê°€
                {'grid': 0.30, 'ridge': 0.60, 'xgboost': 0.10, 'rf': 0.00},  # ì¶”ê°€ ì˜µì…˜
                {'grid': 0.40, 'ridge': 0.50, 'xgboost': 0.10, 'rf': 0.00},  # ë³´ìˆ˜ì  ì˜µì…˜
            ],
            'long': [
                {'grid': 0.10, 'ridge': 0.20, 'xgboost': 0.70, 'rf': 0.00},  # XGBoost ë‹¨ë… â†’ ì•™ìƒë¸”
                {'grid': 0.15, 'ridge': 0.25, 'xgboost': 0.60, 'rf': 0.00},  # ë³´ìˆ˜ì  ì˜µì…˜
                {'grid': 0.05, 'ridge': 0.15, 'xgboost': 0.80, 'rf': 0.00},  # ê³µê²©ì  ì˜µì…˜
            ]
        }

        if args.horizon in ['short', 'both']:
            test_specific_weights('short', improved_weights['short'])

        if args.horizon in ['long', 'both']:
            test_specific_weights('long', improved_weights['long'])

    else:
        # ê¸°ì¡´ ìµœì í™” ì‹¤í–‰
        if args.horizon in ['short', 'both']:
            optimize_ensemble_weights('short', args.weight_step, args.max_weight, args.combinations)

        if args.horizon in ['long', 'both']:
            optimize_ensemble_weights('long', args.weight_step, args.max_weight, args.combinations)

if __name__ == "__main__":
    main()
