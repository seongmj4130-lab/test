"""
ê¸°ì¡´ ë°ì´í„° íŒŒì¼ë“¤ì˜ ê²°ì¸¡ì¹˜ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸
"""

import sys
from datetime import datetime
from pathlib import Path

import numpy as np
import pandas as pd

PROJECT_ROOT = Path(__file__).resolve().parents[1]
sys.path.insert(0, str(PROJECT_ROOT))


def analyze_existing_files():
    """í˜„ì¬ ì¡´ì¬í•˜ëŠ” ë°ì´í„° íŒŒì¼ë“¤ì„ ë¶„ì„"""
    print("ğŸ” ê¸°ì¡´ ë°ì´í„° íŒŒì¼ ê²°ì¸¡ì¹˜ ë¶„ì„")
    print("=" * 80)

    interim_dir = PROJECT_ROOT / "data" / "interim"

    # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” íŒŒì¼ë“¤ ì°¾ê¸°
    existing_files = []
    for file_path in interim_dir.glob("*.parquet"):
        existing_files.append(file_path)
    for file_path in interim_dir.glob("*.csv"):
        existing_files.append(file_path)

    print(f"ë°œê²¬ëœ íŒŒì¼ ìˆ˜: {len(existing_files)}")

    if len(existing_files) == 0:
        print("âŒ ë¶„ì„í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    results = []

    for file_path in existing_files:
        print(f"\nğŸ“Š íŒŒì¼ ë¶„ì„: {file_path.name}")
        print("-" * 50)

        try:
            # íŒŒì¼ ì½ê¸°
            if file_path.suffix == ".parquet":
                df = pd.read_parquet(file_path)
            else:
                df = pd.read_csv(file_path)

            print(f"âœ… ë¡œë“œ ì™„ë£Œ: {len(df):,}í–‰ x {len(df.columns)}ì—´")
            print(
                f"   ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {df.memory_usage(deep=True).sum() / 1024 / 1024:.1f} MB"
            )

            # ê²°ì¸¡ì¹˜ ë¶„ì„
            missing_by_col = df.isnull().sum()
            total_missing = missing_by_col.sum()
            total_cells = len(df) * len(df.columns)
            missing_rate = total_missing / total_cells * 100

            print("\nğŸ” ê²°ì¸¡ì¹˜ ë¶„ì„:")
            print(".1f")
            print(
                f"   ê²°ì¸¡ì¹˜ ìˆëŠ” ì»¬ëŸ¼ ìˆ˜: {len(missing_by_col[missing_by_col > 0])}/{len(df.columns)}"
            )

            # ìƒìœ„ ê²°ì¸¡ì¹˜ ì»¬ëŸ¼
            if len(missing_by_col[missing_by_col > 0]) > 0:
                top_missing = missing_by_col[missing_by_col > 0].nlargest(5)
                print("   ìƒìœ„ ê²°ì¸¡ì¹˜ ì»¬ëŸ¼:")
                for col, count in top_missing.items():
                    rate = count / len(df) * 100
                    print(".1f")

            # ë°ì´í„° íƒ€ì… ë¶„ì„
            dtype_counts = df.dtypes.value_counts()
            print("\nğŸ“‹ ë°ì´í„° íƒ€ì…:")
            for dtype, count in dtype_counts.items():
                print(f"   {dtype}: {count}ê°œ ì»¬ëŸ¼")

            # ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ í†µê³„
            numeric_cols = df.select_dtypes(include=[np.number]).columns
            if len(numeric_cols) > 0:
                print("\nğŸ“ˆ ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ í†µê³„:")
                numeric_stats = df[numeric_cols].describe()
                print(f"   ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ ìˆ˜: {len(numeric_cols)}")
                print(".4f")
                print(".4f")
            # ê²°ê³¼ ì €ì¥
            result = {
                "íŒŒì¼ëª…": file_path.name,
                "í–‰ìˆ˜": len(df),
                "ì—´ìˆ˜": len(df.columns),
                "ê²°ì¸¡ë¥ (%)": missing_rate,
                "ê²°ì¸¡ì…€ìˆ˜": total_missing,
                "ê²°ì¸¡ì»¬ëŸ¼ìˆ˜": len(missing_by_col[missing_by_col > 0]),
                "ìˆ˜ì¹˜í˜•ì»¬ëŸ¼ìˆ˜": len(numeric_cols),
            }
            results.append(result)

        except Exception as e:
            print(f"âŒ ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
            continue

    # ì¢…í•© ë³´ê³ ì„œ
    if results:
        print("\nğŸ“‹ ì¢…í•© ë¶„ì„ ë³´ê³ ì„œ")
        print("=" * 80)

        summary_df = pd.DataFrame(results)
        print(summary_df.to_string(index=False, float_format="%.2f"))

        # ë¬¸ì œì  ë¶„ì„
        print("\nğŸ¯ ë°ì´í„° í’ˆì§ˆ í‰ê°€")
        print("-" * 50)

        avg_missing_rate = summary_df["ê²°ì¸¡ë¥ (%)"].mean()
        files_with_missing = sum(1 for r in results if r["ê²°ì¸¡ë¥ (%)"] > 0)

        print(".1f")
        print(f"ê²°ì¸¡ì¹˜ ìˆëŠ” íŒŒì¼ ìˆ˜: {files_with_missing}/{len(results)}")

        if avg_missing_rate > 10:
            quality = "âŒ ì‹¬ê°í•œ ê²°ì¸¡ì¹˜ ë¬¸ì œ"
        elif avg_missing_rate > 5:
            quality = "âš ï¸ ë³´í†µ ìˆ˜ì¤€ ê²°ì¸¡ì¹˜"
        elif avg_missing_rate > 1:
            quality = "ğŸ”¶ ê²½ë¯¸í•œ ê²°ì¸¡ì¹˜"
        else:
            quality = "âœ… ì–‘í˜¸í•œ ë°ì´í„° í’ˆì§ˆ"

        print(f"ì „ì²´ í’ˆì§ˆ í‰ê°€: {quality}")

        # CSVë¡œ ì €ì¥
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_file = (
            PROJECT_ROOT
            / "artifacts"
            / "reports"
            / f"existing_data_quality_analysis_{timestamp}.csv"
        )
        summary_df.to_csv(output_file, index=False, encoding="utf-8-sig")
        print(f"\nğŸ’¾ ìƒì„¸ ê²°ê³¼ ì €ì¥: {output_file}")

    print(f"\nğŸ† ë¶„ì„ ì™„ë£Œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")


if __name__ == "__main__":
    analyze_existing_files()
