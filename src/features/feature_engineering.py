# -*- coding: utf-8 -*-
"""
í”¼ì³ ì—”ì§€ë‹ˆì–´ë§ ëª¨ë“ˆ

ê¸°ì¡´ í”¼ì³ë¥¼ ê°œì„ í•˜ê³  ìƒˆë¡œìš´ íŒŒìƒ í”¼ì³ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
ëª¨ë“  í”¼ì³ëŠ” ë²¡í„°í™” êµ¬í˜„ìœ¼ë¡œ ì„±ëŠ¥ ìµœì í™”.
"""

import warnings
from typing import Dict, List, Optional

import numpy as np
import pandas as pd

warnings.filterwarnings('ignore')


class FeatureEngineer:
    """
    í”¼ì³ ì—”ì§€ë‹ˆì–´ë§ í´ë˜ìŠ¤

    ê¸°ì¡´ í”¼ì³ ê°œì„  ë° ìƒˆë¡œìš´ íŒŒìƒ í”¼ì³ ìƒì„±
    """

    def __init__(self):
        self.new_features = []

    def create_price_relative_features(self, ohlcv_df: pd.DataFrame) -> pd.DataFrame:
        """
        ê°€ê²© ê¸°ë°˜ í”¼ì³ ê°œì„ : ì ˆëŒ€ ê°€ê²© â†’ ìƒëŒ€ì  ì§€í‘œë¡œ ë³€í™˜

        Args:
            ohlcv_df: OHLCV ë°ì´í„°í”„ë ˆì„ (date, ticker, open, high, low, close, volume)

        Returns:
            ê°œì„ ëœ ê°€ê²© í”¼ì³ë“¤
        """
        df = ohlcv_df.copy()
        features_created = []

        # ê·¸ë£¹ë³„ ê³„ì‚°ì„ ìœ„í•œ ì •ë ¬
        df = df.sort_values(['ticker', 'date'])

        for ticker in df['ticker'].unique():
            mask = df['ticker'] == ticker
            ticker_data = df[mask].copy()

            # 52ì£¼ ìµœê³ /ìµœì €ê°€ ëŒ€ë¹„ ê°€ê²© ìœ„ì¹˜
            ticker_data['close_to_52w_high'] = (
                ticker_data['close'] /
                ticker_data['close'].rolling(252, min_periods=60).max()
            )

            ticker_data['close_to_52w_low'] = (
                ticker_data['close'] /
                ticker_data['close'].rolling(252, min_periods=60).min()
            )

            # ì¼ì¤‘ ê°€ê²© ìœ„ì¹˜ (0~1)
            ticker_data['intraday_price_position'] = (
                (ticker_data['close'] - ticker_data['low']) /
                (ticker_data['high'] - ticker_data['low']).replace(0, np.nan)
            )

            # ê°€ê²© ë³€ë™í­ ë¹„ìœ¨
            ticker_data['price_range_ratio'] = (
                (ticker_data['high'] - ticker_data['low']) /
                ticker_data['close'].shift(1)
            )

            # ì¼ì¤‘ ìƒìŠ¹í­/í•˜ë½í­ ë¹„ìœ¨
            ticker_data['intraday_up_ratio'] = (
                (ticker_data['close'] - ticker_data['open']) /
                (ticker_data['high'] - ticker_data['low']).replace(0, np.nan)
            )

            # ê²°ê³¼ ì €ì¥
            df.loc[mask, ticker_data.columns] = ticker_data

            features_created.extend([
                'close_to_52w_high', 'close_to_52w_low',
                'intraday_price_position', 'price_range_ratio', 'intraday_up_ratio'
            ])

        # NaN ì²˜ë¦¬ ë° ê²°ê³¼ ë°˜í™˜
        result_df = df[['date', 'ticker']].copy()
        for feature in features_created:
            if feature in df.columns:
                result_df[feature] = df[feature].fillna(0.5)  # ì¤‘ë¦½ê°’

        self.new_features.extend(features_created)
        print(f"âœ… ê°€ê²© ìƒëŒ€ì  í”¼ì³ ìƒì„± ì™„ë£Œ: {len(features_created)}ê°œ")

        return result_df[features_created]

    def create_momentum_enhanced_features(self, prices_df: pd.DataFrame) -> pd.DataFrame:
        """
        ëª¨ë©˜í…€ í”¼ì³ ê°•í™”: ë‹¨ìˆœ ìˆ˜ìµë¥  â†’ ê°€ì¤‘/ê°€ì†ë„/ì¡°ì • ì§€í‘œ

        Args:
            prices_df: ê°€ê²© ë°ì´í„° (date, ticker, close)

        Returns:
            ê°•í™”ëœ ëª¨ë©˜í…€ í”¼ì³ë“¤
        """
        df = prices_df.copy()
        features_created = []

        # ê·¸ë£¹ë³„ ê³„ì‚°
        df = df.sort_values(['ticker', 'date'])

        for ticker in df['ticker'].unique():
            mask = df['ticker'] == ticker
            ticker_data = df[mask].copy()

            # ê¸°ë³¸ ìˆ˜ìµë¥  ê³„ì‚°
            ticker_data['returns'] = ticker_data['close'].pct_change()

            # 3ê°œì›” ëª¨ë©˜í…€ ê°•í™”
            momentum_3m = ticker_data['close'] / ticker_data['close'].shift(63) - 1
            ticker_data['momentum_3m_ewm'] = momentum_3m.ewm(span=10).mean()
            ticker_data['momentum_3m_accel'] = momentum_3m - momentum_3m.shift(21)

            # 6ê°œì›” ëª¨ë©˜í…€ ê°•í™”
            momentum_6m = ticker_data['close'] / ticker_data['close'].shift(126) - 1
            ticker_data['momentum_6m_ewm'] = momentum_6m.ewm(span=15).mean()
            ticker_data['momentum_6m_accel'] = momentum_6m - momentum_6m.shift(21)

            # ë³€ë™ì„± ì¡°ì • ëª¨ë©˜í…€ (20ì¼ ë³€ë™ì„± ì‚¬ìš©)
            vol_20d = ticker_data['returns'].rolling(20, min_periods=5).std() * np.sqrt(252)
            ticker_data['momentum_3m_vol_adj'] = momentum_3m * (1 + vol_20d)
            ticker_data['momentum_6m_vol_adj'] = momentum_6m * (1 + vol_20d)

            # ëª¨ë©˜í…€ ì§€ì†ì„± ì§€í‘œ
            ticker_data['momentum_persistence'] = (
                momentum_3m.rolling(10).corr(momentum_6m)
            )

            df.loc[mask, ticker_data.columns] = ticker_data

            features_created.extend([
                'momentum_3m_ewm', 'momentum_3m_accel',
                'momentum_6m_ewm', 'momentum_6m_accel',
                'momentum_3m_vol_adj', 'momentum_6m_vol_adj',
                'momentum_persistence'
            ])

        # NaN ì²˜ë¦¬ ë° ê²°ê³¼ ë°˜í™˜
        result_df = df[['date', 'ticker']].copy()
        for feature in features_created:
            if feature in df.columns:
                result_df[feature] = df[feature].fillna(0)

        self.new_features.extend(features_created)
        print(f"âœ… ëª¨ë©˜í…€ ê°•í™” í”¼ì³ ìƒì„± ì™„ë£Œ: {len(features_created)}ê°œ")

        return result_df[features_created]

    def create_volatility_enhanced_features(self, returns_df: pd.DataFrame) -> pd.DataFrame:
        """
        ë³€ë™ì„± í”¼ì³ ê°œì„ : ë‹¨ë°©í–¥ â†’ ë‹¤ê°ì  ë³€ë™ì„± ì§€í‘œ

        Args:
            returns_df: ìˆ˜ìµë¥  ë°ì´í„° (date, ticker, returns)

        Returns:
            ê°œì„ ëœ ë³€ë™ì„± í”¼ì³ë“¤
        """
        df = returns_df.copy()
        features_created = []

        # ê·¸ë£¹ë³„ ê³„ì‚°
        df = df.sort_values(['ticker', 'date'])

        for ticker in df['ticker'].unique():
            mask = df['ticker'] == ticker
            ticker_data = df[mask].copy()

            # ê¸°ì¡´ ë³€ë™ì„±
            vol_60d = ticker_data['returns'].rolling(60, min_periods=20).std() * np.sqrt(252)

            # ìƒë°©/í•˜ë°© ë³€ë™ì„± ë¶„ë¦¬
            upside_returns = ticker_data['returns'].where(ticker_data['returns'] > 0, 0)
            downside_returns = ticker_data['returns'].where(ticker_data['returns'] < 0, 0)

            ticker_data['upside_volatility_60d'] = (
                upside_returns.rolling(60, min_periods=20).std() * np.sqrt(252)
            )
            ticker_data['volatility_asymmetry'] = (
                ticker_data['upside_volatility_60d'] / (vol_60d + 1e-8)
            )

            # ê¼¬ë¦¬ ìœ„í—˜ ì§€í‘œ
            ticker_data['tail_risk_5pct'] = (
                ticker_data['returns'].rolling(60, min_periods=20).quantile(0.05)
            )
            ticker_data['tail_risk_95pct'] = (
                ticker_data['returns'].rolling(60, min_periods=20).quantile(0.95)
            )

            # ë³€ë™ì„± ì²´ì œ (60ì¼ vs 252ì¼ í‰ê· )
            vol_252d = ticker_data['returns'].rolling(252, min_periods=60).std() * np.sqrt(252)
            ticker_data['volatility_regime'] = vol_60d / (vol_252d + 1e-8)

            # ë³€ë™ì„± ë³€í™”ìœ¨
            ticker_data['volatility_momentum'] = vol_60d / vol_60d.shift(20) - 1

            df.loc[mask, ticker_data.columns] = ticker_data

            features_created.extend([
                'upside_volatility_60d', 'volatility_asymmetry',
                'tail_risk_5pct', 'tail_risk_95pct',
                'volatility_regime', 'volatility_momentum'
            ])

        # NaN ì²˜ë¦¬ ë° ê²°ê³¼ ë°˜í™˜
        result_df = df[['date', 'ticker']].copy()
        for feature in features_created:
            if feature in df.columns:
                result_df[feature] = df[feature].fillna(0)

        self.new_features.extend(features_created)
        print(f"âœ… ë³€ë™ì„± ê°•í™” í”¼ì³ ìƒì„± ì™„ë£Œ: {len(features_created)}ê°œ")

        return result_df[features_created]

    def create_news_enhanced_features(self, news_df: pd.DataFrame) -> pd.DataFrame:
        """
        ë‰´ìŠ¤ í”¼ì³ ê°•í™”: ê°ì„± ë¶„ì„ ì‹¬í™”

        Args:
            news_df: ë‰´ìŠ¤ ë°ì´í„° (date, ticker, news_sentiment, news_volume ë“±)

        Returns:
            ê°•í™”ëœ ë‰´ìŠ¤ í”¼ì³ë“¤
        """
        df = news_df.copy()
        features_created = []

        # ê·¸ë£¹ë³„ ê³„ì‚°
        df = df.sort_values(['ticker', 'date'])

        for ticker in df['ticker'].unique():
            mask = df['ticker'] == ticker
            ticker_data = df[mask].copy()

            # ê°ì„± ê°•ë„ (ê°ì„± Ã— ê±°ë˜ëŸ‰)
            ticker_data['news_intensity'] = (
                abs(ticker_data.get('news_sentiment', 0)) *
                ticker_data.get('news_volume', 1)
            )

            # ê°ì„± ì¼ê´€ì„± (5ì¼ rolling std)
            ticker_data['news_consistency'] = (
                ticker_data.get('news_sentiment', 0).rolling(5, min_periods=1).std()
            )

            # ë‰´ìŠ¤ íŠ¸ë Œë“œ (20ì¼ EWM)
            ticker_data['news_trend'] = (
                ticker_data.get('news_sentiment', 0).ewm(span=20).mean()
            )

            # ë‰´ìŠ¤ ì§€ì†ì„± (60ì¼ EWM)
            ticker_data['news_persistence'] = (
                ticker_data.get('news_sentiment', 0).ewm(span=60).mean()
            )

            df.loc[mask, ticker_data.columns] = ticker_data

            features_created.extend([
                'news_intensity', 'news_consistency',
                'news_trend', 'news_persistence'
            ])

        # NaN ì²˜ë¦¬ ë° ê²°ê³¼ ë°˜í™˜
        result_df = df[['date', 'ticker']].copy()
        for feature in features_created:
            if feature in df.columns:
                result_df[feature] = df[feature].fillna(0)

        self.new_features.extend(features_created)
        print(f"âœ… ë‰´ìŠ¤ ê°•í™” í”¼ì³ ìƒì„± ì™„ë£Œ: {len(features_created)}ê°œ")

        return result_df[features_created]

    def create_interaction_features(self, feature_df: pd.DataFrame) -> pd.DataFrame:
        """
        í”¼ì³ ìƒí˜¸ì‘ìš© ìƒì„±: ì¬ë¬´ + ê¸°ìˆ  ê²°í•©

        Args:
            feature_df: ê¸°ì¡´ í”¼ì³ ë°ì´í„°í”„ë ˆì„

        Returns:
            ìƒí˜¸ì‘ìš© í”¼ì³ë“¤
        """
        df = feature_df.copy()
        features_created = []

        # ì¬ë¬´ + ë³€ë™ì„± ê²°í•©
        if 'roe' in df.columns and 'volatility_60d' in df.columns:
            df['roe_volatility_adj'] = df['roe'] / (df['volatility_60d'] + 1e-8)
            features_created.append('roe_volatility_adj')

        # ê°€ì¹˜ + ëª¨ë©˜í…€ ê²°í•©
        if 'per' in df.columns and 'momentum_3m' in df.columns:
            df['value_momentum_score'] = (
                self._rank_normalize(df['per']) +
                self._rank_normalize(df['momentum_3m'])
            ) / 2
            features_created.append('value_momentum_score')

        # ë‰´ìŠ¤ + ê°€ê²© ì •ë ¬ë„
        if 'news_sentiment' in df.columns and 'momentum_3m' in df.columns:
            df['news_price_alignment'] = (
                df['news_sentiment'] * df['momentum_3m']
            )
            features_created.append('news_price_alignment')

        # NaN ì²˜ë¦¬ ë° ê²°ê³¼ ë°˜í™˜
        result_df = df[['date', 'ticker']].copy()
        for feature in features_created:
            if feature in df.columns:
                result_df[feature] = df[feature].fillna(0)

        self.new_features.extend(features_created)
        print(f"âœ… í”¼ì³ ìƒí˜¸ì‘ìš© ìƒì„± ì™„ë£Œ: {len(features_created)}ê°œ")

        return result_df[features_created]

    def _rank_normalize(self, series: pd.Series) -> pd.Series:
        """ë­í‚¹ ì •ê·œí™” í—¬í¼ í•¨ìˆ˜"""
        return (series.rank() - series.rank().mean()) / series.rank().std()

    def get_new_features_list(self) -> List[str]:
        """ìƒì„±ëœ ìƒˆ í”¼ì³ ëª©ë¡ ë°˜í™˜"""
        return self.new_features.copy()

    def apply_all_enhancements(
        self,
        ohlcv_df: pd.DataFrame,
        fundamental_df: Optional[pd.DataFrame] = None,
        news_df: Optional[pd.DataFrame] = None
    ) -> pd.DataFrame:
        """
        ëª¨ë“  í”¼ì³ ê°œì„  ì ìš©

        Args:
            ohlcv_df: OHLCV ë°ì´í„°
            fundamental_df: ì¬ë¬´ ë°ì´í„° (ì„ íƒ)
            news_df: ë‰´ìŠ¤ ë°ì´í„° (ì„ íƒ)

        Returns:
            ê°œì„ ëœ ëª¨ë“  í”¼ì³ë“¤
        """
        print("ğŸš€ í”¼ì³ ì—”ì§€ë‹ˆì–´ë§ ì‹œì‘...")

        all_features = []

        # 1. ê°€ê²© ê¸°ë°˜ í”¼ì³ ê°œì„ 
        if not ohlcv_df.empty:
            price_features = self.create_price_relative_features(ohlcv_df)
            all_features.append(price_features)

        # 2. ëª¨ë©˜í…€ í”¼ì³ ê°•í™”
        if not ohlcv_df.empty and 'close' in ohlcv_df.columns:
            momentum_features = self.create_momentum_enhanced_features(
                ohlcv_df[['date', 'ticker', 'close']]
            )
            all_features.append(momentum_features)

        # 3. ë³€ë™ì„± í”¼ì³ ê°œì„ 
        if not ohlcv_df.empty:
            returns_df = ohlcv_df.copy()
            if 'close' in returns_df.columns:
                returns_df['returns'] = returns_df.groupby('ticker')['close'].pct_change()

            volatility_features = self.create_volatility_enhanced_features(
                returns_df[['date', 'ticker', 'returns']]
            )
            all_features.append(volatility_features)

        # 4. ë‰´ìŠ¤ í”¼ì³ ê°•í™”
        if news_df is not None and not news_df.empty:
            news_features = self.create_news_enhanced_features(news_df)
            all_features.append(news_features)

        # 5. í”¼ì³ ìƒí˜¸ì‘ìš© (ê¸°ì¡´ í”¼ì³ë“¤ê³¼ ê²°í•©)
        if fundamental_df is not None and not fundamental_df.empty:
            interaction_features = self.create_interaction_features(fundamental_df)
            all_features.append(interaction_features)

        # ê²°ê³¼ í•©ì¹˜ê¸°
        if all_features:
            result_df = pd.concat(all_features, axis=1)

            # date, ticker ì¶”ê°€ (ì²« ë²ˆì§¸ dfì—ì„œ ê°€ì ¸ì˜´)
            if all_features[0] is not None and not all_features[0].empty:
                result_df = result_df.join(
                    all_features[0][['date', 'ticker']],
                    how='left'
                )

            print(f"âœ… ì´ {len(self.new_features)}ê°œ í”¼ì³ ìƒì„± ì™„ë£Œ")
            return result_df

        return pd.DataFrame()


# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
def test_feature_engineering():
    """í”¼ì³ ì—”ì§€ë‹ˆì–´ë§ í…ŒìŠ¤íŠ¸"""
    import sys
    sys.path.append('.')
    from src.utils.config import load_config
    from src.utils.io import load_artifact

    # ë°ì´í„° ë¡œë“œ
    cfg = load_config('configs/config.yaml')
    interim_dir = cfg['paths']['base_dir'] / 'data' / 'interim'

    ohlcv_df = load_artifact(interim_dir / 'ohlcv_daily')
    panel_df = load_artifact(interim_dir / 'panel_merged_daily')

    # í”¼ì³ ì—”ì§€ë‹ˆì–´ë§ ì ìš©
    engineer = FeatureEngineer()
    enhanced_features = engineer.apply_all_enhancements(
        ohlcv_df=ohlcv_df,
        fundamental_df=panel_df
    )

    print(f"ìƒì„±ëœ í”¼ì³ë“¤: {engineer.get_new_features_list()}")
    print(f"í”¼ì³ ë°ì´í„° shape: {enhanced_features.shape}")

    return enhanced_features


if __name__ == "__main__":
    test_feature_engineering()
