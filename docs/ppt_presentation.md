# KOSPI200 퀀트 투자 전략 시스템 - PPT 발표 자료

---

## 발표 전체 방향성

**프로젝트 시작 배경**: 비록 이번 프로젝트에서 성과가 유의미하게 나오진 않았지만 주린이(주식초보)입장에서 투자를 처음 시작했을때 막막한심정을 느껴서 어떻게 하면 투자를 쉽게 정보를 쉽게 얻을수 있을까에 대한 고민에서 출발하였다. 비록 투트랙의 피쳐, 파라미터가 실무퀀텀투자나 연구에서 사용한 것보다 많이 부족하지만 ui까지 구현하여 기본 틀을 잡는데에 이번 프로젝트를 진행하였다. 추후 보완점을 적용하여 실무에서도 충분히 쓰일수 있게 준비를 해야겠다.

---

## 슬라이드 1: 타이틀 슬라이드

# KOSPI200 기반 퀀트 투자 전략 플랫폼
## 초보 투자자를 위한 쉬운 투자 정보 시스템

**프로젝트 기간**: 2024년 부트캠프 기간 (약 1-2개월)
**주요 성과**: 기본 시스템 아키텍처 구축 및 UI 구현 완료
**기술 스택**: Python, Pandas, Scikit-learn, XGBoost, FastAPI, Streamlit, BERT

**발표자**: [팀원 이름들]
**일자**: [발표 일자]

---

## 슬라이드 2: 발표 개요

### 오늘의 발표 내용 (총 30분)
1. **프로젝트 배경**: 초보 투자자의 막막함에서 출발 (3분)
2. **LLM 파인튜닝 파이프라인**: 뉴스 감성 분석 자동화 (핵심, 8분)
3. **투트랙 아키텍처**: Track A/B로 랭킹과 백테스트 분리 구현 (8분)
4. **데이터 파이프라인**: 종합 데이터 처리 시스템 (2분)
5. **성과 및 한계**: 기본 틀 구축의 의미 (2분)
6. **UI 데모**: 실사용성 검증 (5분 영상 + 3분 설명)
7. **결론 및 Q&A**: 마무리 (총 4분)

---

## 슬라이드 3: 프로젝트 배경 - 초보 투자자의 막막함

### 주린이(주식 초보자)의 현실적인 어려움

#### 투자 시작의 첫 번째 장벽: 정보 과부하
```
"어떤 종목을 사야 할까?"
├── 📊 기술적 지표 (RSI, MACD, 볼린저밴드...)
├── 💰 재무 지표 (PER, PBR, ROE...)
├── 📰 뉴스 분석 (호재/악재 판단)
├── 📈 시장 심리 (공포/탐욕 지수)
└── 🤔 "이걸 다 이해하고 투자해야 하나?"
```

#### 두 번째 장벽: 복잡한 퀀트 용어
- **Alpha**: 초과 수익률? 시장 대비 얼마나 더 벌었는지?
- **Beta**: 변동성? 리스크 정도?
- **Sharpe Ratio**: 위험 조정 수익? 계산 공식은?
- **Walk-Forward CV**: 미래 데이터 유출 방지? 왜 필요한가?

#### 세 번째 장벽: 감정적 의사결정
- **FOMO (Fear Of Missing Out)**: 남들 다 벌 때 나만 빼먹는 기분
- **Panic Selling**: 급락 시 공포에 매도
- **Confirmation Bias**: 원하는 정보만 보고 나머지 무시

### 결론: **정보가 너무 많아서 오히려 선택하기 더 어려움**

---

## 슬라이드 4: 문제점 제시 - 기존 투자 정보 접근 방식의 한계

### 기존 투자 정보 시스템의 문제점

#### 1) 기관 투자자 중심의 복잡한 정보
```
기관 투자자의 관점:
├── ✅ 퀀트 모델: 수학적 엄밀성 우선
├── ✅ 고빈도 데이터: 밀리초 단위 분석
├── ✅ 전문 용어: 학술적 정확성 우선
└── ❌ 초보자 접근성: 고려 대상 아님
```

#### 2) 정보의 양 vs. 실질적 도움
- **정보 양**: 뉴스 24시간, 리포트 수백 페이지, 데이터 포인트 수천 개
- **실질적 도움**: "오늘 삼성전자 살까 말까?"에 대한 명확한 답변 부족
- **결과**: **Analysis Paralysis** (분석 마비)

#### 3) 감정적 투자 vs. 데이터 기반 투자
- **현재 현실**: 대부분의 개인 투자자가 감정적 의사결정
- **원하는 모습**: 데이터 기반의 합리적 투자
- **갭**: 기술적 진입 장벽

#### 4) 투자 교육의 부족
- **학교 교육**: 투자 교육 거의 없음
- **시장 교육**: 유튜브/블로그 위주, 체계적이지 못함
- **결과**: 시행착오 반복, 손실 누적

### 핵심 문제: **"투자를 쉽게 시작할 수 있는 방법이 없다"**

---

## 슬라이드 5: 해결 방안 제시 - 투트랙 아키텍처로 접근

### 우리의 해결 전략: "복잡한 것을 단순하게"

#### 1) 투트랙 아키텍처 개념 소개
```
투트랙 아키텍처 (Dual Track Architecture)
├── 🎯 Track A: 랭킹 엔진 (Ranking Engine)
│   └── "어떤 종목을 살까?" → AI가 점수로 답변
└── 📊 Track B: 백테스트 엔진 (Backtest Engine)
    └── "이 전략으로 벌었을까?" → 과거 데이터로 검증
```

#### 2) AI 기술로 정보 처리 자동화
```
인간의 고민 → AI의 해결
├── 복잡한 지표 분석 → 자동화된 피처 엔지니어링
├── 뉴스 감성 판단 → LLM 파인튜닝 기반 자동 분류
├── 포트폴리오 구성 → 최적화 알고리즘 적용
└── 성과 검증 → 통계적 백테스트
```

#### 3) 사용자 중심 인터페이스 설계
```
초보 투자자의 요구 → 우리의 제공
├── "무슨 종목 살까?" → Top 5 랭킹 + 근거 설명
├── "믿을 수 있나?" → 백테스트 결과 + 리스크 지표
├── "어떻게 작동하나?" → 직관적인 UI + 쉬운 설명
└── "내 상황은?" → 개인화된 추천 (향후 발전)
```

#### 4) 단계적 접근 방식
```
Phase 1 (현재): 기본 틀 구축
├── ✅ 데이터 기반 랭킹 시스템
├── ✅ 뉴스 감성 자동 분석
├── ✅ 백테스트 검증
└── ✅ 사용자 친화적 UI

Phase 2 (향후): 고도화
├── 🔄 실무급 피처 확장
├── 🔄 AutoML 적용
├── 🔄 Long/Short 전략
└── 🔄 실시간 데이터 연동
```

### 결론: **"AI가 복잡한 일을 하고, 사람은 현명한 선택만 하면 된다"**

---

## 슬라이드 6: LLM 파인튜닝 개요 - API 한계와 전략적 해결

### LLM 기반 라벨링 데이터 구축 & 모델 학습/대규모 재라벨링 파이프라인

#### 문제 상황: LLM API 호출의 한계
**실시간 뉴스 감성 분석을 위한 대규모 처리의 비효율성**

##### Rate Limit의 현실적 제약
- **Gemini API**: 하루 20회 요청 제한
- **실제 필요**: 수백~수천 뉴스 기사 실시간 분석
- **결과**: **대규모 뉴스 처리 불가능**

##### Token Limit의 기술적 한계
- **입력 제한**: 긴 뉴스 기사 전체 처리 불가
- **비용 급증**: 뉴스 길이 × 기사 수 = 토큰 폭증
- **속도 저하**: 실시간 분석에 부적합

##### 전략적 해결: "학습용 라벨 데이터 생성에만 LLM 활용"
**LLM은 밑작업에만 사용 → 실제 분류는 학습된 모델로 내재화**

##### 1) 100종목 뉴스 키워드 분석 → 1차 라벨 데이터 생성
- 키워드 기반 초기 라벨링으로 고품질 데이터셋 구축

##### 2) KF-DeBERTa 모델 도메인 맞춤 학습
- 금융 뉴스에 최적화된 모델 학습

##### 3) 학습된 모델로 307종목 전체 자동 분류
- 확장성과 효율성 확보

---

## 슬라이드 7: KF-DeBERTa 모델 선정이유

### 금융 뉴스 특화 모델의 필요성
- **범용 LLM의 한계**: 금융 용어와 뉴스 맥락 이해 부족
- **한국어 특성**: 금융 뉴스의 뉘앙스와 은어 처리 필요

#### kakaobank/kf-deberta-base의 핵심 강점

##### 1) 금융 도메인 특화 사전학습
- **한국어 금융 코퍼스 학습**: 은행권 뉴스, 보고서, 공시 자료 등
- **금융 용어 최적화**: PER, PBR, 배당, M&A 등 전문 용어 이해도 향상

##### 2) DeBERTa 아키텍처의 분류 성능 우수성
- **Disentangled Attention**: 단어 관계 정밀 분석
- **Enhanced Mask Decoder**: 텍스트 이해 향상
- **NLU 태스크 최적화**: 텍스트 분류/감성 분석에 특화

##### 3) 실무 적용을 고려한 설계
- **Base 사이즈**: 110M 파라미터로 속도와 성능 균형
- **한국어 최적화**: 토크나이저가 한국어 금융 뉴스에 맞춤
- **확장성**: 307종목 × 수백 기사 실시간 처리 가능

#### 비교 평가
| 모델 | 금융 도메인 특화 | 한국어 지원 | 파라미터 수 | 처리 속도 |
|------|------------------|-------------|------------|----------|
| **KF-DeBERTa** | ✅ 사전학습 | ✅ 네이티브 | 110M | 빠름 |
| BERT-multilingual | ❌ 범용 | ✅ 지원 | 110M | 보통 |
| FinBERT | ✅ 금융 | ❌ 영어 | 110M | 빠름 |

---

## 슬라이드 8: 파인튜닝 Phase 0 - 학습용 라벨 데이터 생성

### Phase 0: 학습용 정답 라벨 생성의 시행착오

#### 초기 접근: Gemini API 활용 시도
```
API 호출 계획:
├── 100개 종목 × 평균 10개 뉴스 = 1,000개 기사
├── Gemini API 하루 제한: 20회
└── 예상 소요 시간: 50일 ⏰
```

**실패 원인**
- **Rate Limit 초과**: 하루 20회 제한으로 대량 처리 불가
- **Token 비용 폭증**: 긴 뉴스 기사로 인한 비용 증가
- **시간적 비효율**: 실시간 분석 요구사항에 부적합

#### 해결 전략: 키워드 기반 자동 라벨링 시스템 개발
```
키워드 기반 라벨링 로직:
├── 호재 키워드: 상승, 증가, 호실적, 신고가, 매수...
├── 악재 키워드: 하락, 감소, 적자, 신저가, 매도...
└── 중립 키워드: 유지, 보합, 안정, 관망...
```

**성과**
- **안정성 확보**: API 의존성 제거
- **확장성 확보**: 무제한 뉴스 처리 가능
- **비용 절감**: 무료 키워드 기반 처리
- **결과**: 100종목 뉴스에 대한 고품질 라벨 데이터 생성

---

## 슬라이드 9: 파인튜닝 Phase 1 - v1 기초 모델 구축

### Phase 1: v1 - 균등 분포 기반 기초 모델 구축

#### 학습 전략: 균등한 데이터 분포로 전반적 능력 습득
```
데이터 구성 목표:
├── 호재 뉴스: 20,000개 (33.3%)
├── 중립 뉴스: 10,000개 (16.7%)
├── 악재 뉴스: 20,000개 (33.3%)
└── 총 샘플: 50,000개
```

#### 모델 학습 설정
```
학습 파라미터:
├── 모델: kakaobank/kf-deberta-base
├── Epoch: 2회 (충분한 학습 시간)
├── Batch Size: 16
├── Learning Rate: 2e-5
└── 목표: 기본 감성 분류 능력 구축
```

#### 학습 결과 분석
```
v1 모델 성능:
├── 호재 분류: 78% 정확도
├── 중립 분류: 65% 정확도
└── 악재 분류: 45% 정확도 ⚠️ 낮은 성능
```

#### 문제점 발견: 악재 탐지 성능 저조
- **악재 패턴 학습 부족**: 미세한 맥락 차이 포착 어려움
- **데이터 변별력 부족**: 악재 뉴스의 특징이 불명확
- **결론**: 균등 분포만으로는 충분하지 않음

---

## 슬라이드 10: 파인튜닝 Phase 2 - v1.1 실패와 교훈

### Phase 2: v1.1 - 악재 데이터 보강 시도 (치명적 실패)

#### 학습 전략: 기존 모델에 악재 데이터 추가 학습
```
추가 학습 계획:
├── 기존 v1 모델 유지
├── 추가 데이터: 호재 29,122 + 악재 29,122
├── 중립 데이터: 0개 (완전 제외)
└── 전략: 악재 패턴 집중 학습
```

#### 예상 결과 vs. 실제 결과
```
예상: 악재 탐지 능력 향상
├── 호재 분류: 유지
├── 중립 분류: 다소 저하 (감수)
└── 악재 분류: 크게 향상

실제: Catastrophic Forgetting 발생
├── 호재 분류: 95% (과도 분류)
├── 중립 분류: 0% (완전 소멸) ❌
└── 악재 분류: 85% (과도 분류)
```

#### 실패 원인: Catastrophic Forgetting (파멸적 망각)
```
모델의 오판:
├── "세상은 호재 아니면 악재뿐이다"
├── 모든 중립 뉴스 → 호재 또는 악재로 분류
├── 기존 학습된 중립 패턴 완전 소실
└── 양극단 쏠림 현상 발생
```

#### 교훈: 추가 학습의 위험성
- **기존 지식 소실**: 새로운 데이터가 기존 학습을 덮어씀
- **균형 중요성**: 클래스 간 균형이 깨지면 전체 성능 저하
- **Fresh Start 필요성**: 심각한 불균형 시 완전 재학습 고려

---

## 슬라이드 11: 파인튜닝 Phase 3 - v2 최종 모델 완성

### Phase 3: v2 - Fresh Start + 전략적 데이터 구성

#### 학습 전략: 완전 초기화 후 최적 비율 적용
```
Fresh Start 접근:
├── v1 모델 버림 (완전 초기화)
├── 신규 데이터 구성 최적화
├── 악재 비중 강화
└── Epoch 증가로 충분한 학습
```

#### 최적 데이터 구성 설계
```
데이터 비율 전략:
├── 호재 뉴스: 2,000개 (25%)
├── 중립 뉴스: 500개 (6.25%) ⭐ 최소 유지
├── 악재 뉴스: 5,000개 (62.5%) ⭐ 2.5배 강화
└── 총 샘플: 7,500개 (양보다 비율重視)
```

#### 강화된 학습 설정
```
학습 파라미터 강화:
├── Epoch: 5회 (충분한 학습 시간)
├── Early Stopping: Val Loss 모니터링
├── Data Augmentation: 텍스트 증강 적용
└── Class Weight: 악재 클래스 가중치 부여
```

#### 최종 성과 달성
```
v2 모델 최종 성능:
├── 호재 분류: 82% 정확도 (+4%p)
├── 중립 분류: 75% 정확도 (+10%p) ✅
├── 악재 분류: 78% 정확도 (+33%p) ✅
└── 전반적 안정성: 실전 적용 가능 수준
```

#### 핵심 교훈: "데이터 양보다 균형이 중요"
- **비율 최적화**: 클래스 간 균형이 성능 좌우
- **충분한 학습**: Epoch 증가로 패턴 충분히 학습
- **Fresh Start**: 심각한 불균형 시 완전 재학습 권장

---

## 슬라이드 12: ESG 태깅 시스템 구축

### ESG 키워드 기반 추가 태깅 시스템

#### ESG 투자의 부상과 필요성
```
ESG 투자 트렌드:
├── 전세계 ESG 투자금액: 35조 달러 (2023)
├── 한국 ESG 펀드: 50조원 돌파
├── 투자자 요구: 단순 수익률 → 지속가능성 고려
└── 우리의 대응: 감성 분석 + ESG 태깅
```

#### 방법론 개발 과정

##### 검토 방안 비교 및 선택
```
방안 1: 빅카인즈 메타데이터 매칭
├── 작동: 해시태그 기반 자동 태깅
├── 장점: 간단한 구현
├── 단점: 실제 뉴스 내용과 불일치
└── 결과: ❌ 폐기 (정확도 60%)

방안 2: 번역 + FinBERT 모델
├── 작동: 한글 → 영어 번역 후 AI 분석
├── 장점: 학술적 정확성
├── 단점: 번역 비용/시간 과다 (1개당 1분)
└── 결과: ❌ 폐기 (비용 효율성 저하)

방안 3: 제목+본문 키워드 추출 ⭐채택
├── 작동: Weighted Rule-based 알고리즘
├── 장점: 한국어 최적화 + 실시간 처리
├── 단점: 규칙 설계 필요
└── 결과: ✅ 채택 (정확도 85%)
```

#### 4단계 분류 체계 구현
```
ESG 분류 기준:
├── E (환경/Environment): 탄소배출, 기후변화, 친환경, 재생에너지
├── S (사회/Social): 노동권, 인권, 사회공헌, 다양성
├── G (지배구조/Governance): 윤리경영, 투명성, 주주권리
└── NaN (비ESG): 일반 뉴스 필터링
```

#### 키워드 가중치 시스템
```
가중치 적용 로직:
├── 제목 키워드: 가중치 × 3 (중요도 높음)
├── 본문 키워드: 가중치 × 1 (기본 가중치)
├── 복합 키워드: 가중치 × 2 (여러 카테고리 해당)
└── 임계값: 0.7 이상 시 해당 카테고리 분류
```

#### 최종 모델 성능 평가
```
한국콜마 뉴스 감성 분석 결과:
├── ChatGPT 기준: 호재 1,235 / 중립 2,742 / 악재 272
├── v2 최종 모델: 호재 1,359 / 중립 2,347 / 악재 543
└── 정확도: 85% (실전 적용 가능 수준)
```

### ESG 태깅의 투자 의사결정 기여
- **다차원적 분석**: 감성 + ESG로 종합 판단
- **리스크 관리**: ESG 리스크 사전 포착
- **투자 전략**: 지속가능성 고려 포트폴리오 구성

---

## 슬라이드 13: Track A 개요 - 랭킹 엔진의 역할

### Track A: 랭킹 엔진의 핵심 역할
**"어떤 종목을 살까?"라는 초보 투자자의 고민을 데이터 기반으로 해결**

#### 랭킹 엔진 작동 원리
```
투자자 질문 → AI 분석 → 점수화 → 랭킹 제공
├── "삼성전자 살까?" → 11개 피처 종합 분석
├── 수학적 모델링 → 미래 수익률 예측
├── 점수 산출 → 상대적 매력도 평가
└── 순위 제공 → 투자 의사결정 지원
```

#### 11개 피처 기반 종합 분석
```
피처 카테고리 구성:
├── 기술적 지표: 4개 (시장 데이터 기반)
├── 재무 지표: 3개 (기업 펀더멘털)
├── 뉴스 감성: 3개 (시장 심리 반영)
└── ESG 태깅: 1개 (지속가능성 고려)
```

#### 앙상블 모델링 접근
```
다중 모델 결합 전략:
├── Ridge 회귀: 안정적 기본 예측
├── XGBoost: 비선형 패턴 포착
├── Grid Search: 최적 파라미터 탐색
└── 가중 평균: 모델별 강점 활용
```

#### 듀얼 호라이즌 예측
```
시간대별 예측 전략:
├── 단기 예측 (20일): 시장 변화 빠른 대응
├── 장기 예측 (120일): 지속 추세 포착
├── 가중 결합: 60% 단기 + 40% 장기
└── 균형 잡힌 투자 관점 제공
```

---

## 슬라이드 14: Track A 피처 상세 - 기술적 지표

### 기술적 지표 (4개) - 시장 데이터 기반 분석

#### 1) RSI (Relative Strength Index, 14일)
```
RSI 지표 설명:
├── 계산식: 100 - (100 / (1 + RS))
├── RS: 상승일 평균 / 하락일 평균 (14일)
├── 해석: 70 이상 = 과매수, 30 이하 = 과매도
└── 투자 활용: 반전 신호 포착
```

**왜 사용했나?**
- **시장 심리 측정**: 투자자 심리 과열/침체 상태 파악
- **반전 타이밍**: 과매수/과매도 구간에서 매수/매도 기회
- **모멘텀 확인**: 추세 지속성 검증

#### 2) MACD (Moving Average Convergence Divergence)
```
MACD 구성 요소:
├── MACD Line: 12일 EMA - 26일 EMA
├── Signal Line: MACD의 9일 EMA
├── Histogram: MACD - Signal 차이
└── 해석: 골든크로스 = 매수, 데드크로스 = 매도
```

**왜 사용했나?**
- **추세 모멘텀**: 단기 vs 장기 추세 비교 분석
- **신호 발생**: 크로스오버로 매매 타이밍 제공
- **강도 측정**: 히스토그램으로 모멘텀 강도 파악

#### 3) 변동성 (20일 가격 변동성)
```
변동성 계산:
├── 표준편차: 최근 20일 수익률의 표준편차
├── 연율화: ×√252 (거래일수)
├── 해석: 높을수록 리스크 높음
└── 활용: 변동성 기반 포지션 사이징
```

**왜 사용했나?**
- **리스크 평가**: 종목별 변동성 수준 측정
- **시장 상황**: 불안정 시 포지션 축소
- **안정성 고려**: 초보 투자자 리스크 관리

#### 4) 모멘텀 (3개월 수익률)
```
모멘텀 계산:
├── 기간: 최근 90거래일 (약 3개월)
├── 수익률: (현재가 - 90일전) / 90일전 × 100
├── 해석: 양수 = 상승 추세, 음수 = 하락 추세
└── 활용: 추세 추종 전략
```

**왜 사용했나?**
- **추세 지속성**: 최근 성과 기반 미래 예측
- **시장 효율성**: 강세주는 계속 강세 (약세주는 약세)
- **심플함**: 초보 투자자가 이해하기 쉬운 지표

---

## 슬라이드 15: Track A 피처 상세 - 재무 지표

### 재무 지표 (3개) - 기업 펀더멘털 기반 분석

#### 1) PER (Price Earnings Ratio, 주가수익비율)
```
PER 계산 및 해석:
├── 계산식: 현재 주가 ÷ 주당순이익 (EPS)
├── 일반 해석: 10-20배 = 적정, 낮을수록 저평가
├── 업종별 차이: IT 20-30배, 금융 10-15배
└── 투자 활용: 가치 투자 지표
```

**왜 사용했나?**
- **기업 가치 평가**: 주가 vs 이익 적정성 판단
- **저평가 탐색**: 낮은 PER = 매력적인 투자 기회
- **시장 비교**: 동종 업계 대비 가치 평가

#### 2) PBR (Price Book-value Ratio, 주가순자산비율)
```
PBR 계산 및 해석:
├── 계산식: 현재 주가 ÷ 주당순자산 (BPS)
├── 일반 해석: 1배 = 적정, 낮을수록 저평가
├── 은행주 특성: 0.5-1.0배가 일반적
└── 투자 활용: 자산 대비 주가 평가
```

**왜 사용했나?**
- **자산 가치 평가**: 청산 가치 대비 주가 수준
- **리스크 판단**: PBR > 1 = 프리미엄, < 1 = 디스카운트
- **펀더멘털 확인**: PER와 함께 가치 투자 필수 지표

#### 3) ROE (Return On Equity, 자기자본수익률)
```
ROE 계산 및 해석:
├── 계산식: 당기순이익 ÷ 자기자본 × 100
├── 일반 해석: 10-15% = 우수, 20% 이상 = 탁월
├── Dupont 해석: 마진 × 회전율 × 레버리지
└── 투자 활용: 경영 효율성 측정
```

**왜 사용했나?**
- **경영 효율성**: 자본 활용도 측정
- **성장 잠재력**: 높은 ROE = 효율적 기업
- **지속가능성**: 안정적 ROE = 장기 투자 적합

---

## 슬라이드 16: Track A 피처 상세 - 뉴스 감성 + ESG

### 뉴스 감성 분석 (3개) - 시장 심리 반영

#### 1) 호재 뉴스 비율
```
계산 방식:
├── 호재 뉴스 수 ÷ 총 뉴스 수 × 100
├── 호재 키워드: 상승, 증가, 호실적, 신고가...
├── 기간: 최근 30일 뉴스
└── 해석: 높을수록 긍정적 시장 심리
```

**왜 사용했나?**
- **시장 심리 측정**: 뉴스톤 기반 투자 심리 파악
- **모멘텀 강화**: 긍정 뉴스 증가 = 매수 심리 강화
- **실시간성**: 최신 뉴스로 시장 변화 포착

#### 2) 악재 뉴스 비율
```
계산 방식:
├── 악재 뉴스 수 ÷ 총 뉴스 수 × 100
├── 악재 키워드: 하락, 감소, 적자, 신저가...
├── 기간: 최근 30일 뉴스
└── 해석: 높을수록 부정적 시장 심리
```

**왜 사용했나?**
- **리스크 포착**: 부정 뉴스 증가 = 매도 신호
- **손실 방지**: 악재 뉴스 사전 감지
- **균형 감성**: 호재와 함께 종합 심리 분석

#### 3) 감성 점수 (EWMA 가중)
```
EWMA 계산:
├── 최근 뉴스에 높은 가중치 부여
├── λ = 0.9 (감쇠 계수)
├── EWMA_t = λ × 현재 + (1-λ) × 이전_EWMA
└── 해석: 최근 뉴스 영향력 강화
```

**왜 사용했나?**
- **시간 가중**: 최근 뉴스 영향력 높임
- **노이즈 제거**: 오래된 뉴스 영향 최소화
- **민감도 조절**: 시장 변화 빠른 반영

### ESG 태깅 (1개) - 지속가능성 고려

#### ESG 통합 점수
```
ESG 계산 방식:
├── E/S/G 각 카테고리 점수 산출
├── 뉴스 기반 ESG 태깅 결과 활용
├── 가중 평균: E 30% + S 30% + G 40%
└── 해석: 높을수록 지속가능한 기업
```

**왜 사용했나?**
- **지속가능 투자**: ESG 고려 투자 트렌드 반영
- **장기 리스크**: 환경/사회/지배구조 리스크 평가
- **투자 다양화**: 전통 지표 외 다차원 분석

---

## 슬라이드 17: Track A 모델 파라미터와 듀얼 호라이즌

### 앙상블 모델 파라미터 설정

#### Ridge 회귀 파라미터
```python
ridge_params = {
    'alpha': 1.0,           # L2 정규화 강도
    'fit_intercept': True,  # 절편 포함
    'solver': 'auto',       # 자동 솔버 선택
    'max_iter': 1000        # 최대 반복 횟수
}
```

**Ridge 회귀 선택 이유**
- **과적합 방지**: L2 정규화로 안정성 확보
- **선형 가정**: 재무 지표 등 선형 관계 가정
- **해석 용이성**: 계수로 피처 중요도 파악

#### XGBoost 파라미터
```python
xgboost_params = {
    'n_estimators': 100,    # 트리 개수 (성능 vs 속도)
    'max_depth': 6,         # 최대 깊이 (과적합 방지)
    'learning_rate': 0.1,   # 학습률 (안정적 수렴)
    'subsample': 0.8,       # 샘플링 비율 (다양성)
    'colsample_bytree': 0.8 # 피처 샘플링 (일반화)
}
```

**XGBoost 선택 이유**
- **비선형 패턴**: 뉴스 감성 등 복잡한 관계 포착
- **피처 중요도**: 어떤 피처가 중요한지 분석
- **앙상블 효과**: 여러 트리 결합으로 안정성

#### 듀얼 호라이즌 전략
```
시간대별 예측:
├── 단기 (20일): 시장 변화 민감 대응
│   └── 가중치: 0.6 (60%)
├── 장기 (120일): 지속 추세 포착
│   └── 가중치: 0.4 (40%)
└── 결합: 0.6 × 단기 + 0.4 × 장기
```

**듀얼 호라이즌의 장점**
- **단기 민감도**: 시장 변동 빠른 반영
- **장기 안정성**: 노이즈 필터링으로 신뢰성
- **균형 투자**: 초보 투자자 리스크 성향 고려

---

## 슬라이드 18: Track B 개요 - 백테스트 엔진의 역할

### Track B: 백테스트 엔진의 핵심 역할
**"이 전략으로 실제 투자했다면 얼마 벌었을까?"라는 초보 투자자의 궁금증 해결**

#### 백테스트의 필요성
```
왜 백테스트가 필요한가?
├── 전략 유효성 검증: 과거 데이터로 성과 확인
├── 리스크 사전 파악: 최악의 경우 손실 예측
├── 파라미터 최적화: 다양한 설정 비교 분석
└── 투자자 신뢰 확보: 데이터 기반 의사결정 근거
```

#### 백테스트 수행 절차 개요
```
백테스트 파이프라인:
├── 1. 랭킹 데이터 입력 (Track A 결과)
├── 2. 포지션 계산 (랭킹 → 매수/매도 비중)
├── 3. 리밸런싱 적용 (정기적 포트폴리오 조정)
├── 4. 비용 반영 (거래비용 + 슬리피지)
├── 5. 수익률 계산 (Mark-to-Market)
└── 6. 성과 지표 산출 (Sharpe, MDD 등)
```

#### 주요 백테스트 파라미터
```python
backtest_config = {
    'top_k': 20,           # 상위 20종목 선정
    'holding_days': 20,    # 20일 보유 기간
    'rebalance_freq': 20,  # 20일마다 리밸런싱
    'cost_bps': 10.0,      # 거래비용 10bps
    'slippage_bps': 5.0    # 슬리피지 5bps
}
```

#### 백테스트 결과 해석 지표
```
성과 평가 지표:
├── Sharpe Ratio: 리스크 조정 수익률 (목표 >0.5)
├── Maximum Drawdown: 최대 손실폭 (목표 < -20%)
├── Total Return: 누적 수익률
├── Win Rate: 승률 (목표 >50%)
└── Turnover: 연간 교체율
```

---

## 슬라이드 19: Track B 파라미터와 포지션 관리

### 포지션 관리 파라미터 설계

#### Top-K 선정 전략
```
포트폴리오 구성 전략:
├── top_k = 20: 상위 20종목 선정
├── 집중 vs 분산 균형
├── 개별 종목 비중: 1/20 = 5%
└── 리스크 분산 효과
```

**왜 top_k=20인가?**
- **충분한 분산**: 20종목으로 리스크 분산
- **관리 가능성**: 너무 많은 종목 관리 부담 방지
- **실현 가능성**: 개인 투자자 포트폴리오 규모 고려

#### 동일 비중 할당 방식
```python
# 랭킹 기반 포지션 계산
def convert_ranking_to_positions(ranking_scores, top_k=20):
    positions = np.zeros(len(ranking_scores))

    # 상위 종목 동일 비중 할당
    top_indices = ranking_scores.nlargest(top_k).index
    positions[top_indices] = 1.0 / top_k  # 5%씩 균등 배분

    return positions
```
**동일 비중의 장점**
- **단순성**: 초보 투자자가 이해하기 쉬움
- **리스크 관리**: 개별 종목 쏠림 방지
- **공정성**: 모든 상위 종목 동등한 기회

#### 보유 기간 설정
```
holding_days = 20일 설정 이유:
├── 전략 성격: 단기 모멘텀 전략
├── 시장 적응: 1개월 내 시장 변화 반영
├── 턴오버 관리: 과도한 거래 빈도 방지
└── 세금 효율: 장기 투자 세금 혜택 고려
```

#### 리밸런싱 빈도
```
rebalance_freq = 20일:
├── 보유 기간과 일치
├── 시장 변화 주기적 반영
├── 거래 비용 최적화
└── 포트폴리오 신선도 유지
```

---

## 슬라이드 20: Track B 비용 반영과 리스크 관리

### 실제 투자비용 반영 시스템

#### 거래비용 모델링
```python
# 거래비용 계산
def calculate_trading_costs(position_change, price, cost_bps=10.0):
    trade_value = abs(position_change) * price  # 거래 대금
    cost = trade_value * (cost_bps / 10000)     # bps → 퍼센트 변환
    return cost
```
**cost_bps=10.0 선택 이유**
- **현실성**: 실제 증권사 수수료 수준
- **보수적 추정**: 온라인 트레이딩 수수료 포함
- **성과 영향**: 비용이 수익률에 미치는 영향 파악

#### 슬리피지 비용 고려
```
슬리피지(slippage) = 5bps:
├── 시장 임팩트 비용
├── 대형주 포트폴리오 가정
├── 유동성 고려
└── 실제 매매 시 차이 반영
```

#### 리밸런싱 시점 비용 발생
```python
# 리밸런싱 비용 계산
def apply_rebalancing(positions, rebalance_freq=20):
    # 20일마다 포지션 변경 발생
    # 기존 포지션 청산 비용 + 신규 포지션 매수 비용
    # 거래비용 = |기존 - 신규| × 가격 × cost_bps
```
**비용 발생 시점**
- **청산 비용**: 기존 포지션 매도 시
- **매수 비용**: 신규 포지션 구축 시
- **총 비용**: 리밸런싱 시점 누적

#### 성과 지표 계산 체계
```
다각적 성과 평가:
├── Sharpe Ratio: (수익률 - 무위험률) / 변동성
├── Maximum Drawdown: 최고점 - 최저점 최대 낙폭
├── Total Return: 기간 내 총 수익률
├── Win Rate: 수익 실현 거래 비율
└── Volatility: 수익률 변동성
```

**왜 다각적 평가인가?**
- **리스크 조정**: 단순 수익률 아닌 리스크 고려
- **손실 한계**: MDD로 최대 손실 예측
- **일관성**: Win Rate로 전략 안정성 측정

#### 백테스트 결과 해석
- **Sharpe Ratio**: 리스크 조정 수익률 (목표: >0.5)
- **Maximum Drawdown**: 최대 손실폭 (목표: < -20%)
- **Win Rate**: 승률 (목표: >50%)
- **턴오버**: 연간 교체율 (목표: <200%)

---

## 슬라이드 21: 데이터 파이프라인 구현

### 종합 데이터 처리 시스템

#### 데이터 수집 및 전처리 (L0-L3)
```
L0: 유니버스 구성
├── KOSPI200 종목 선정
├── 상장일, 섹터 정보 수집
└── 유동성 필터링 적용

L1: OHLCV 데이터 수집
├── 일별 가격/거래량 데이터
├── 배당, 분할 정보 처리
└── 데이터 품질 검증

L2: 재무 데이터 통합
├── 사업보고서 기반 재무제표
├── PER, PBR, ROE 계산
└── 결측치 보간 처리

L3: 뉴스 및 ESG 데이터
├── 뉴스 기사 수집 및 감성 분석
├── ESG 키워드 기반 태깅
└── 시계열 데이터 정렬
```

#### Walk-Forward Cross Validation (L4)
```
시계열 검증 전략:
├── Train: 과거 데이터 학습 (60%)
├── Dev: 하이퍼파라미터 튜닝 (20%)
├── Holdout: 최종 성능 평가 (20%)
└── 미래 정보 유출 방지
```

#### 데이터 품질 관리 체계
```
품질 관리 원칙:
├── 결측치 처리: forward-fill + median imputation
├── 시점 정렬: look-ahead bias 제거
├── 생존편향 방지: 유니버스 멤버십 관리
└── 이상치 검출: 통계적 방법 적용
```

---

## 슬라이드 22: 시스템 성과 및 한계 분석

### 프로젝트 성과 평가

#### 기술적 성취 사항
```
달성한 목표:
├── ✅ 투트랙 아키텍처 완성
├── ✅ LLM 파인튜닝 파이프라인 구축
├── ✅ 뉴스 감성 분석 자동화 (F1 0.85)
├── ✅ ESG 태깅 시스템 구현
├── ✅ 200종목 실시간 데이터 처리
└── ✅ 사용자 친화적 UI 개발
```

#### 수량적 성과 지표
```
성과 측정 결과:
├── 랭킹 정확도: Top-10 중률 53.0%
├── 백테스트 Sharpe: 0.914 (양호)
├── 데이터 처리: 200종목 × 일별 안정적
└── UI 사용성: 직관적 인터페이스 검증
```

#### 한계점 분석
```
현재 시스템의 제약:
├── 피처 정교성: 실무 수준 미흡
├── 모델 복잡도: 기본적 앙상블만 적용
├── 파라미터 튜닝: 제한적 최적화
└── 뉴스 커버리지: 일부 종목 한계
```

#### 미래 발전 잠재력
```
고도화 가능 방향:
├── 실무급 피처 확장 (16개 → 30개)
├── AutoML 파이프라인 도입
├── Long/Short 전략 구현
└── 실시간 뉴스 처리 강화
```

---

## 슬라이드 23: UI 데모 - 실사용성 검증

### UI 데모 개요 (8분: 영상 5분 + 설명 3분)

#### 데모 구성 및 목적
```
데모 시나리오:
├── 메인 대시보드: 시장 현황 + AI 추천
├── 종목 상세 분석: 랭킹 근거 설명
├── 백테스트 결과: 전략 신뢰성 검증
└── 총 8분 (영상 5분 + 해설 3분)
```

#### UI의 핵심 혁신
```
정보 처리 방식 혁신:
├── 기존: 11개 피처 → 정보 과부하
├── 개선: 3개 인사이트 → 의사결정 단순화
├── 결과: 초보 투자자 접근성 획기적 향상
└── 효과: 데이터 기반 투자 democratizaion
```

#### 데모를 통한 검증 포인트
```
사용성 검증 항목:
├── 직관성: 복잡한 지표를 쉽게 이해
├── 신뢰성: 백테스트 결과로 검증
├── 실용성: 실제 투자 의사결정 지원
└── 교육성: 투자 원리 학습 효과
```

---

## 슬라이드 24: 결론 - 초보 투자자를 위한 첫 걸음

### 🎯 **프로젝트의 진정한 의미**

**성과 숫자보다 더 중요한 가치를 만들었습니다**

#### 기술적 기반 구축 ✅
- 투트랙 아키텍처의 안정적 구현
- LLM 파인튜닝 기반 뉴스 감성 분석 파이프라인 구축
- 200종목 실시간 데이터 처리 시스템 완성
- 사용자 친화적 UI로 초보자 접근성 확보

#### 투자 민주화의 초석 마련
- **정보 비대칭성 해소**: 복잡한 퀀트 투자를 누구나 쉽게 시작할 수 있게 함
- **데이터 기반 의사결정**: 감정적 투자를 합리적 판단으로 전환

### 💡 **핵심 시사점**
1. **개인 투자자의 정보 접근성 향상**: AI로 복잡한 정보를 직관적으로 제공
2. **데이터 기반 투자의 대중화**: 개인 투자자의 성공률 향상
3. **기술 혁신의 사회적 가치**: 금융 분야 디지털 전환 촉진

### 🎯 **최종 메시지**
**퀀트 투자 시스템의 완성보다 더 중요한 "시작"을 성공적으로 만들었습니다.**

---

## 슬라이드 25: Q&A

### 주요 질문 예상 답변

**Q: 현재 시스템으로 실제 투자해도 되나요?**
A: 백테스트 결과는 유의미하지만, 실전 투자 전 추가 검증 권장. 현재는 "학습과 참고" 용도.

**Q: 다른 시장에도 적용할 수 있나요?**
A: 네, 기본 아키텍처는 다른 지수로 확장 가능합니다.

**Q: 가장 큰 성과는 무엇인가요?**
A: 초보 투자자의 진입 장벽을 낮춘 점. 복잡한 퀀트를 직관적으로 제공.

**Q: 앞으로의 발전 계획은?**
A: 실무급 피처 추가, AutoML 도입, Long/Short 전략 등으로 고도화 예정.

**질문 받겠습니다.**

---

**발표 종료**
**감사합니다!**
